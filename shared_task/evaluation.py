
### a standalone script for evaluation

import argparse
import json

def read_json_line(path):
    output = []
    with open(path, 'r') as f:
        for line in f:
            output.append(json.loads(line))
    return output

parser = argparse.ArgumentParser()
parser.add_argument("-p", "--prediction", help="Path to the predictions generated by the system", type=str, required=True)
parser.add_argument("-g", "--golden", help="Path to the golden labels", type=str, required=True)
args = parser.parse_args()


def main():

    ## read in files
    system_predictions = read_json_line(args.prediction)
    golden_predictions = read_json_line(args.golden)
    golden_predictions_dict = {}
    for each_line in golden_predictions:
        golden_predictions_dict[each_line['id']] = each_line

    ## question tags
    question_tag = golden_predictions[0]['golden_annotation']

    ## evaluation
    result = []
    for each_task in question_tag:
        # evaluate curr task
        curr_task = {}
        TP, FP, FN = 0.0, 0.0, 0.0
        for each_line in system_predictions:
            curr_sys_pred = [i.lower() for i in each_line['predicted_annotation'][each_task] if i != 'Not Specified']
            curr_golden_ann = [i.lower() for i in golden_predictions_dict[each_line['id']]['golden_annotation'][each_task] if i != 'Not Specified']
            # print(curr_sys_pred, curr_golden_ann)
            if len(curr_golden_ann) > 0:
                for predicted_chunk in curr_sys_pred:
                    if predicted_chunk in curr_golden_ann:
                        TP += 1  # True positives are predicted spans that appear in the gold labels.
                    else:
                        FP += 1  # False positives are predicted spans that don't appear in the gold labels.
                for gold_chunk in curr_golden_ann:
                    if gold_chunk not in curr_sys_pred:
                        FN += 1  # False negatives are gold spans that weren't in the set of spans predicted by the model.
            else:
                if len(curr_sys_pred) > 0:
                    for predicted_chunk in curr_sys_pred:
                        FP += 1  # False positives are predicted spans that don't appear in the gold labels.

        # print
        if TP + FP == 0:
            P = 0.0
        else:
            P = TP / (TP + FP)

        if TP + FN == 0:
            R = 0.0
        else:
            R = TP / (TP + FN)

        if P + R == 0:
            F1 = 0.0
        else:
            F1 = 2.0 * P * R / (P + R)

        curr_task["F1"] = F1
        curr_task["P"] = P
        curr_task["R"] = R
        curr_task["TP"] = TP
        curr_task["FP"] = FP
        curr_task["FN"] = FN
        N = TP + FN
        curr_task["N"] = N

        # print(curr_task)
        result.append(curr_task)

        # print
        print(each_task.replace('.Response', ''))
        print('P:', curr_task['P'], 'R:', curr_task['R'], 'F1:', curr_task['F1'])
        print('=======')


if __name__ == '__main__':
    main()